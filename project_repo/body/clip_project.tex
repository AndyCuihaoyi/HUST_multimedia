\section{视频相关编程实验}

\subsection{ffmpeg视频帧分割}

\subsubsection{实验要求}
使用 ffmpeg 工具包(https://ffmpeg.org/download.html)，将《教父》片段视频解析为一张一张的图片，解码时请将 fps设置为5或者10即可，否则生成图片数量过多，请展示ffmpeg解析的命令行代码，并展示示例视频所解压的首帧、中间帧和未尾帧。

\subsubsection{具体实现}
视频帧分割是视频内容分析的前置基础步骤，本模块通过调用 FFmpeg 工具实现视频帧的批量提取，核心目标是将输入视频按指定帧率（FPS）转换为独立的 JPG 格式帧文件，并通过异常处理机制保证流程健壮性。该功能由 \texttt{extract\_frames()} 函数实现，具体设计与实现如下：

\paragraph{功能说明}
该函数完成以下核心操作：
\begin{enumerate}
    \item 目录自动创建：检测帧输出目录（\texttt{FRAME\_DIR}）是否存在，不存在则创建，避免写入失败；
    \item FFmpeg 命令构造：拼接包含输入路径、提取帧率、输出质量、文件命名规则的命令行参数；
    \item 子进程执行：通过 \texttt{subprocess} 模块调用 FFmpeg 工具，阻塞执行并捕获输出/错误信息；
    \item 异常处理：捕获 FFmpeg 执行错误（如视频路径错误、文件损坏、帧率非法等），输出错误详情并终止程序；执行成功则返回布尔值标识提取完成。
\end{enumerate}
\lstset{
    language=Python,                % 指定代码语言为Python
    basicstyle=\small\ttfamily,     % 基础字体样式
    keywordstyle=\color{blue}\bfseries,  % 关键字样式（蓝色、加粗）
    commentstyle=\color{green!60!black}, % 注释样式（绿色）
    stringstyle=\color{red},        % 字符串样式（红色）
    numbers=left,                   % 行号显示在左侧
    numberstyle=\tiny\color{gray},  % 行号样式（小号、灰色）
    frame=single,                   % 代码框为单实线
    breaklines=true,                % 自动换行
    showstringspaces=false,         % 不显示字符串中的空格符号
    columns=flexible,               % 列宽自适应
    captionpos=b,                   % 标题位于代码框底部
    escapeinside={/*@}{@*/}         % 允许在代码中嵌入LaTeX命令
}

\vspace{\baselineskip}
\begin{lstlisting}[caption={FFmpeg 视频帧提取核心函数}, label={code:extract_frames}]
import os
import subprocess

# 全局配置参数
VIDEO_PATH = "godfather_clip.mp4" 
FRAME_DIR = "frames_output"      
FPS = 5                            

def extract_frames():

    os.makedirs(FRAME_DIR, exist_ok=True)
    
    ffmpeg_cmd = [
        "ffmpeg",             
        "-i", VIDEO_PATH,          
        "-r", str(FPS),          
        "-q:v", "2",               （1-31，数值越小质量越高）
        os.path.join(FRAME_DIR, "frame_%04d.jpg")
    ]
    
    try:
        # 执行 FFmpeg 命令
        result = subprocess.run(
            ffmpeg_cmd,
            check=True,            # 命令返回非0状态码时抛出异常
            capture_output=True,   # 捕获标准输出/标准错误
            text=True              # 将输出转为字符串（而非字节流）
        )
        print("=== 视频帧提取完成 ===")
        return True
    except subprocess.CalledProcessError as e:
        print(f"=== 帧提取失败 ===")
        print(f"错误详情：{e.stderr.strip()}")
        exit(1)
\end{lstlisting}

\subsubsection{结果分析}
分割后获取了三个帧：首帧，中间帧和未尾帧。将这三个帧的结果和视频拉动进度条的截图进行对比，可以发现分割出来的帧与视频进度条对应位置的画面内容是一致的，说明视频帧分割功能实现正确。图\ref{fig:three_frames}展示了本次实验提取的目标镜头首帧、中间帧、末尾帧的可视化结果：
% 可根据需求调整章节层级，如放在\subsubsection{P帧的压缩算法}的结果部分
\begin{figure}[!htbp]
    \centering  % 整体居中
    % 第一个子图：frame_cnt_1.png
    \subfigure[帧分割结果1]{
        \includegraphics[width=0.45\textwidth, keepaspectratio]{images/frame_cut_1.png}
        \label{subfig:frame_cnt_1}
    }
    \hfill  % 子图间均匀分布（无多余间距）
    % 第二个子图：frame_cnt_2.png
    \subfigure[帧分割结果2]{
        \includegraphics[width=0.45\textwidth, keepaspectratio]{images/frame_cut_2.png}
        \label{subfig:frame_cnt_2}
    }
    \caption{帧分割结果}  % 总标题（可根据实际内容修改）
    \label{fig:frame_cnt}  % 总标签（全文引用）
\end{figure}
\begin{figure}[!htbp]
    \centering  % 整体居中
    % 第一个子图：首帧
    \subfigure[首帧]{
        \includegraphics[width=0.3\textwidth]{images/first_frame_5.png}  % 路径+格式（根据实际格式改jpg/png）
        \label{subfig:first_frame}
    }
    \hfill  % 子图间水平填充（均匀分布）
    % 第二个子图：中间帧
    \subfigure[中间帧]{
        \includegraphics[width=0.3\textwidth]{images/mid_frame_5.png}
        \label{subfig:mid_frame}
    }
    \hfill
    % 第三个子图：末尾帧
    \subfigure[末尾帧]{
        \includegraphics[width=0.3\textwidth]{images/last_frame_5.png}
        \label{subfig:last_frame}
    }
    \caption{目标镜头提取的三帧结果（FPS=5）}  % 总标题
    \label{fig:three_frames}  % 总标签（全文引用）
\end{figure}

\begin{figure}[!htbp]
    \centering  % 整体居中
    % 第一个子图：真实首帧
    \subfigure[真实首帧]{
        \includegraphics[width=0.3\textwidth, keepaspectratio]{images/first_frame_real.png}
        \label{subfig:first_frame_real}
    }
    \hfill  % 子图间均匀分布
    % 第二个子图：真实中间帧
    \subfigure[真实中间帧]{
        \includegraphics[width=0.3\textwidth, keepaspectratio]{images/mid_frame_real.png}
        \label{subfig:mid_frame_real}
    }
    \hfill
    % 第三个子图：真实末尾帧
    \subfigure[真实末尾帧]{
        \includegraphics[width=0.3\textwidth, keepaspectratio]{images/last_frame_real.png}
        \label{subfig:last_frame_real}
    }
    \caption{视频进度条截取的真实参考帧}  % 总标题
    \label{fig:real_frames}  % 总标签（全文引用）
\end{figure}

经视觉对比，FFmpeg 分割生成的真实截取帧画面完全一致，最终验证本次视频帧分割结果准确有效，可作为后续 MPEG 压缩实验的基础数据。


\subsection{镜头和场景分割}

\subsubsection{实验要求}
镜头和场景分割：观察获取的图像帧，请说明视频中有哪些位置（按原视频中的时间）出现了镜头变换，并指出变换的类型，然后请将相同场景的镜头放在一起，以层次结构图展示。

编程：使用基于影色直方图的方法检测境头边界，并附上代码和帧问差值的柱状图展示，设定合适國值后展示所检测涯到的镜头变换位置，并请说明基于直方图的镜头变换检测方法可以如何进一步凌进?


\subsubsection{具体实现}

\paragraph{1. 单帧特征直方图计算（calc\_frame\_hist）}
该函数用于提取单帧图像的多维特征直方图，作为镜头分割的特征基础。核心逻辑为：读取帧图像并缩放至固定尺寸，转换为 YCrCb 颜色空间后计算亮度（Y）、色度（Cr/Cb）的直方图，同时计算灰度图的梯度幅值直方图；对所有直方图归一化后，按权重融合为一维特征直方图，若帧读取失败则返回空直方图。

\begin{lstlisting}[caption={单帧特征直方图计算核心代码}, label={code:calc_frame_hist}]
import cv2
import numpy as np

def calc_frame_hist(frame_path):
    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"警告：无法读取帧文件 {frame_path}，返回空直方图")
        return np.zeros((18 * 8 * 8 + 16,))

    frame = cv2.resize(frame, (320, 240))
    ycbcr = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycbcr)

    # 计算颜色分量直方图
    hist_y = cv2.calcHist([y], [0], None, [32], [0, 256])
    hist_cr = cv2.calcHist([cr], [0], None, [16], [0, 256])
    hist_cb = cv2.calcHist([cb], [0], None, [16], [0, 256])

    # 计算梯度幅值直方图
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    grad_mag = np.sqrt(sobel_x ** 2 + sobel_y ** 2)
    hist_grad = cv2.calcHist([grad_mag.astype(np.uint8)], [0], None, [16], [0, 256])

    # 归一化并融合直方图
    hist_y = cv2.normalize(hist_y, hist_y).flatten()
    hist_cr = cv2.normalize(hist_cr, hist_cr).flatten()
    hist_cb = cv2.normalize(hist_cb, hist_cb).flatten()
    hist_grad = cv2.normalize(hist_grad, hist_grad).flatten()

    hist = np.concatenate([hist_y * 0.4, hist_cr * 0.2, hist_cb * 0.2, hist_grad * 0.2])
    return hist
\end{lstlisting}

\paragraph{2. 帧间直方图差值计算}
该函数批量处理所有帧文件，调用 \texttt{calc\_frame\_hist} 生成每帧的特征直方图，计算相邻帧的 Bhattacharyya 距离（直方图差值）；对差值序列进行归一化、滑动窗口平滑处理，并结合差值梯度调整最终差值，输出差值序列及帧时间、编号等元数据，为镜头分割提供量化依据。

\begin{lstlisting}[caption={帧间直方图差值计算核心代码}, label={code:calc_hist_diff}]
import os
import numpy as np
import cv2

def calc_hist_diff():
    frame_files = sorted([f for f in os.listdir(FRAME_DIR) if f.startswith("frame_") and f.endswith(".jpg")])
    if len(frame_files) < 2:
        print("帧数量不足，无法计算差值！")
        exit(1)

    hist_list, frame_times, frame_indices = [], [], []
    for frame_name in frame_files:
        hist = calc_frame_hist(os.path.join(FRAME_DIR, frame_name))
        hist_list.append(hist)
        # 解析帧编号与时间戳
        try:
            frame_idx = int(frame_name.split("_")[1].split(".")[0])
            frame_times.append(frame_idx / FPS)
            frame_indices.append(frame_idx)
        except (IndexError, ValueError):
            frame_times.append(len(frame_times) / FPS)
            frame_indices.append(len(frame_indices) + 1)

    # 计算帧间直方图差值
    hist_diff = [cv2.compareHist(hist_list[i-1], hist_list[i], cv2.HISTCMP_BHATTACHARYYA) for i in range(1, len(hist_list))]
    hist_diff = np.array(hist_diff)

    # 归一化 + 平滑处理 + 梯度调整
    if np.max(hist_diff) > 0:
        hist_diff = (hist_diff - np.min(hist_diff)) / (np.max(hist_diff) - np.min(hist_diff))
    if len(hist_diff) >= SMOOTH_WINDOW:
        kernel = np.ones(SMOOTH_WINDOW) / SMOOTH_WINDOW
        hist_diff = np.convolve(hist_diff, kernel, mode='same')
    
    diff_deriv = np.gradient(hist_diff)
    hist_diff = hist_diff * 0.5 + np.abs(diff_deriv) * 0.5

    return hist_diff, frame_times, frame_files, frame_indices
\end{lstlisting}

\paragraph{3. 镜头分割与短镜头合并（split\_shots\_by\_frames）}
该函数是镜头分割的核心逻辑：基于帧间直方图差值序列，以设定阈值识别镜头边界，划分初始镜头；对长度小于阈值的短镜头进行合并，最终输出结构化的镜头信息（包含镜头ID、帧范围、时间范围、帧文件范围），完成从帧差值到镜头的映射。

\begin{lstlisting}[caption={镜头分割与短镜头合并核心代码}, label={code:split_shots_by_frames}]
import numpy as np

def split_shots_by_frames(hist_diff, frame_files, frame_indices, threshold):
    shots = []
    shot_id = 1
    start_frame_idx = int(frame_files[0].split("_")[1].split(".")[0])

    # 帧数量不足时直接返回整段为单个镜头
    if len(hist_diff) < BASE_WINDOW_LEN:
        shots.append({
            "镜头ID": shot_id,
            "帧范围": [start_frame_idx, int(frame_files[-1].split("_")[1].split(".")[0])],
            "时间范围": [0.0, round(len(frame_files) / FPS, 1)],
            "帧文件范围": f"{frame_files[0]} ~ {frame_files[-1]}"
        })
        return shots

    # 计算基准窗口均值，检测镜头边界
    base_mean = np.mean(hist_diff[:BASE_WINDOW_LEN])
    comp_start = 3
    while comp_start + COMP_WINDOW_LEN <= len(hist_diff):
        comp_mean = np.mean(hist_diff[comp_start:comp_start + COMP_WINDOW_LEN])
        if abs(comp_mean - base_mean) > threshold:
            bound_idx = comp_start + COMP_WINDOW_LEN // 2
            end_frame_idx = frame_indices[bound_idx] - 1
            # 记录当前镜头
            shots.append({
                "镜头ID": shot_id,
                "帧范围": [start_frame_idx, end_frame_idx],
                "时间范围": [round(start_frame_idx/FPS,1), round(end_frame_idx/FPS,1)],
                "帧文件范围": f"{frame_files[start_frame_idx-1]} ~ {frame_files[end_frame_idx-1]}"
            })
            start_frame_idx = frame_indices[bound_idx]
            shot_id += 1
        comp_start += STEP

    # 补充最后一个镜头
    last_frame_idx = int(frame_files[-1].split("_")[1].split(".")[0])
    shots.append({
        "镜头ID": shot_id,
        "帧范围": [start_frame_idx, last_frame_idx],
        "时间范围": [round(start_frame_idx/FPS,1), round(last_frame_idx/FPS,1)],
        "帧文件范围": f"{frame_files[start_frame_idx-1]} ~ {frame_files[-1]}"
    })

    # 合并短镜头
    merged_shots = []
    prev_shot = shots[0]
    for shot in shots[1:]:
        curr_shot_frames = shot["帧范围"][1] - shot["帧范围"][0] + 1
        if curr_shot_frames <= STEP:
            prev_shot = {
                "镜头ID": prev_shot["镜头ID"],
                "帧范围": [prev_shot["帧范围"][0], shot["帧范围"][1]],
                "时间范围": [prev_shot["时间范围"][0], shot["时间范围"][1]],
                "帧文件范围": f"{prev_shot['帧文件范围'].split(' ~ ')[0]} ~ {shot['帧文件范围'].split(' ~ ')[1]}"
            }
        else:
            merged_shots.append(prev_shot)
            prev_shot = shot
    merged_shots.append(prev_shot)

    # 重新编号镜头ID
    for idx, merged_shot in enumerate(merged_shots):
        merged_shot["镜头ID"] = idx + 1

    print(f"合并前镜头数：{len(shots)} | 合并后镜头数：{len(merged_shots)}")
    return merged_shots
\end{lstlisting}

\subsubsection{结果分析与改进策略}
图\ref{fig:frame_diff_dist}为视频帧间增强型差值的分布（经归一化、滑动窗口平滑及梯度调整优化），是镜头分割的核心量化依据，结合该图可对分割结果进行如下分析：

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{images/hist_diff_bar.png}  % 替换为实际图片路径
    \caption{视频帧间增强型差值分布}
    \label{fig:frame_diff_dist}
\end{figure}

\paragraph{1. 分布图核心信息解释}
该图横轴为「相邻帧对」（标注了帧对编号及对应视频时间，如“1→2 (0.2s)”表示第1帧与第2帧的差值，对应视频0.2秒位置）；纵轴为「归一化帧间差值」（反映相邻帧内容的差异程度，值越大表示内容变化越显著）；红色虚线为镜头分割阈值（$\text{阈值}=0.06$），蓝色柱形为优化后的增强型帧间差值。


\paragraph{2. 镜头边界识别分析}
帧间差值超过阈值（0.06）的区域对应镜头切换的边界，从图中可识别出典型边界位置：
\begin{itemize}
    \item 帧对$1 \to 2$（对应时间$0.2\text{s}$）：差值显著高于阈值，是视频起始处的首个镜头边界；
    \item 帧对$101 \to 102$（对应时间$20.2\text{s}$）、$201 \to 202$（对应时间$40.2\text{s}$）：差值突破阈值，对应视频内容的中期镜头切换；
    \item 帧对$401 \to 402$（对应时间$80.2\text{s}$）、$501 \to 502$（对应时间$100.2\text{s}$）：差值大幅高于阈值，是视频后期的关键镜头边界。
\end{itemize}
而图中多数区域的差值低于阈值，说明这些相邻帧属于同一镜头内的连续内容（仅存在细微视觉变化，非镜头切换）。


\paragraph{3. 分割结果的合理性验证}
结合镜头分割函数（\texttt{split\_shots\_by\_frames}）的逻辑，该分布图支撑的分割结果具备以下合理性：
\begin{enumerate}
    \item 边界准确性：差值超阈值的区域均对应视频内容的显著变化（如场景切换、主体跳转），与实际镜头切换逻辑一致；
    \item 噪声鲁棒性：优化后的差值序列（归一化+平滑+梯度调整）过滤了同一镜头内的细微波动（如图中$51 \to 52$等帧对的小幅度差值），避免了“伪边界”导致的过度分割；
    \item 镜头完整性：通过短镜头合并逻辑，最终输出的镜头长度均大于步长阈值（$\text{STEP}=3$），无碎片化的无效镜头，保证了分割结果的实用性。
\end{enumerate}

\paragraph{4. 分割结果}
图\ref{fig:cut_with_line}展示了基于该帧间差值分布图的镜头分割结果，可见核心镜头边界均准确识别，分割后的镜头既覆盖了所有内容跳转场景，又避免了过度分割，符合视频镜头的实际组织逻辑。
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{images/cut_with_line.png}  % 替换为实际图片路径
    \caption{视频帧间增强型差值分布}
    \label{fig:cut_with_line}
\end{figure}

\paragraph{5. 进一步改进策略}
针对当前基于帧间直方图差值的镜头分割方法存在的局限性（如固定阈值适配性差、单一特征鲁棒性不足等），提出以下4点改进策略，以提升分割精度与场景适配能力：

\subparagraph{特征融合的帧间差值计算}
当前方法仅融合了YCrCb颜色特征与梯度幅值特征，对低对比度、相似色彩的镜头切换场景识别能力不足。改进思路为：新增光流场特征（捕捉帧间运动信息）、LBP纹理特征（描述局部纹理变化）、SIFT关键点匹配特征（量化特征点的匹配度），采用加权融合策略（如颜色特征权重0.3、光流特征0.3、纹理特征0.2、梯度特征0.2）重构帧间差值计算模型；通过实验标定不同特征在不同场景（如静态场景、快速运动场景）下的最优权重，提升差值对镜头切换的表征能力。预期效果：降低相似色彩/低对比度场景下的漏检率，提升分割准确率≥5%。

\subparagraph{自适应动态阈值调整机制}
当前方法采用全局固定阈值判定镜头边界，无法适配视频不同时段的内容特性（如前期静态场景差值低、后期运动场景差值高）。改进思路为：基于视频内容的先验分析，将视频划分为若干时间窗口（如每10秒为一个窗口），计算每个窗口内帧间差值的均值与标准差，采用“均值+1.5倍标准差”的动态阈值替代全局固定阈值；同时引入滞后阈值（上升阈值>下降阈值），避免单一帧差值波动导致的伪边界。预期效果：减少固定阈值下的过度分割/欠分割问题，提升边界判定的鲁棒性。

\subparagraph{上下文感知的边界验证}
当前方法仅基于局部窗口的差值均值判定边界，未考虑时序上下文的连续性。改进思路为：对初步检测到的候选边界，构建长度为5~10帧的时序上下文窗口，验证窗口内差值的变化趋势（如镜头切换后差值应快速回落至低水平）；若候选边界后无连续的低差值帧，则判定为“伪边界”并剔除；同时对漏检的低差值镜头切换（如淡入淡出），通过检测帧间特征的渐进式变化（而非突变）补充边界。预期效果：过滤90\%以上的伪边界，补齐淡入淡出等软切换场景的漏检边界。



\subsubsection{结果总结}

基于该帧间差值分布图的镜头分割结果，准确识别了视频中的5处核心镜头边界，分割后的镜头既覆盖了所有内容跳转场景，又避免了过度分割，符合视频镜头的实际组织逻辑，可为后续MPEG压缩实验提供清晰的镜头数据划分。


\subsection{MPEG 压缩实验}
选取视频中某一镜头作为实验数据，将该镜头的首帧、中间帧和末尾帧设定为 MPEG 压缩中的 I 帧（Intra Frame，帧内编码帧），开展以下两组编程实验：

\subsubsection{实验要求}
\paragraph{编程一：I 帧的 JPEG 压缩实现}
对选取的 3 张 I 帧图像执行 JPEG 压缩流程，具体步骤如下：
\begin{enumerate}
    \item 将 RGB 图像转换为 YUV 颜色空间（采用 YUV4:2:0 采样格式）；
    \item 将 Y、U、V 分量分别划分为 $8 \times 8$ 的像素块；
    \item 对每个 $8 \times 8$ 块执行离散余弦变换（DCT）；
    \item 采用 JPEG 标准量化表对 DCT 系数进行量化；
    \item 对量化后的系数执行 Z 字形（Zig-Zag）扫描，将二维系数转换为一维序列；
    \item 对一维序列执行 Huffman 编码完成压缩。
\end{enumerate}
要求：展示上述流程的关键代码片段，并给出代码运行结果的验证数据（无需冗余数据，仅展示核心运行结果即可）。

\paragraph{编程二：P 帧的预测编码压缩实现}
选取中间帧对应的 I 帧作为参考帧，选取该 I 帧的后一帧作为 P 帧（Predictive Frame，帧间预测编码帧），实现 P 帧压缩算法，具体步骤如下：
\begin{enumerate}
    \item 对 P 帧中的每个 $8 \times 8$ 图像块，在参考 I 帧中对应位置周围 $64 \times 64$ 范围内遍历所有 $8 \times 8$ 图像块，计算待编码块与每个候选块的均方误差（MSE），选取 MSE 最小的块作为最佳匹配块；
    \item 计算 P 帧中每个 $8 \times 8$ 图像块与其最佳匹配块的像素差值，对该差值重复编程一中 I 帧的完整编码流程（DCT 变换→量化→Z 字形扫描→Huffman 编码）。
\end{enumerate}
要求：截取核心代码片段并解释其功能，辅以关键中间结果数据（如 MSE 计算结果、差值块数据等）说明流程有效性；最终给出 I 帧相对原始 RGB 数据的压缩率，以及 P 帧相对其原始 RGB 数据的压缩率。
\subsubsection{具体实现}

\lstset{
    language=Python,
    basicstyle=\small\ttfamily,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    showstringspaces=false,
    columns=flexible
}

\paragraph{I帧JPEG压缩}
\subparagraph{算法简介}
I帧（Intra Frame，帧内编码帧）是MPEG压缩的核心参考帧，其JPEG压缩算法通过去除图像空间冗余实现数据压缩。核心逻辑为：将RGB图像转换为YUV颜色空间（聚焦亮度Y分量以简化计算），对Y分量按$8 \times 8$尺寸分块后执行离散余弦变换（DCT），将空域数据转换为频域数据；通过JPEG标准亮度量化表对DCT系数量化（保留低频、舍弃高频冗余），再经Z字形扫描将二维系数转为一维序列，结合游程编码和zlib熵编码完成压缩，最终通过原始数据与压缩后数据的比值计算压缩率。

\subparagraph{代码逻辑描述}
代码实现了简化版I帧JPEG压缩流程：首先读取RGB图像并转换为亮度Y分量（中心化处理以适配DCT变换），补全图像尺寸为8的倍数避免分块越界；逐$8 \times 8$块执行DCT变换和量化，输出前2个块的量化结果作为中间验证数据；对量化系数执行Z字形扫描和游程编码，将编码结果转为字节流后用zlib压缩；最后计算并输出原始RGB数据大小、压缩后数据大小及压缩率，完整覆盖JPEG压缩的核心步骤。

\begin{lstlisting}[caption={I帧JPEG压缩核心代码}, label={code:i_frame_compress}]
# 核心：8x8分块 + DCT变换 + 量化
dct_quant_blocks = []
for i in range(0, h_pad, 8):
    for j in range(0, w_pad, 8):
        block = Y_padded[i:i+8, j:j+8]
        dct_block = cv2.dct(block)  # DCT变换
        quant_block = np.round(dct_block / JPEG_LUMA_QUANT_TABLE)  # 量化
        dct_quant_blocks.append(quant_block)

# 核心：Z字形扫描 + 游程编码
run_length_data = []
for block in dct_quant_blocks:
    zigzag_block = block.flatten()[ZIGZAG_ORDER]  # Z字形扫描
    zero_count = 0
    for val in zigzag_block:
        if val == 0:
            zero_count += 1
        else:
            run_length_data.append((zero_count, val))  # 游程编码
            zero_count = 0
    run_length_data.append((-1, -1))  # 块结束标记

# zlib压缩 + 压缩率计算
byte_data = b''
for (zero, val) in run_length_data:
    zero_int = int(zero)
    val_int = int(val)
    byte_data += zero_int.to_bytes(2, byteorder='little', signed=True) + val_int.to_bytes(2, byteorder='little', signed=True)
compressed_data = zlib.compress(byte_data)
compression_ratio = (img_array.nbytes / 1024) / (len(compressed_data) / 1024)
\end{lstlisting}

\paragraph{P帧的压缩算法}
\subparagraph{算法简介}
P帧（Predictive Frame，帧间预测编码帧）利用视频帧间的时间冗余实现压缩，核心依赖参考I帧的块匹配策略：对P帧的每个$8 \times 8$块，在参考I帧对应位置$48 \times 64$范围内遍历所有$8 \times 8$候选块，通过均方误差（MSE）筛选最佳匹配块；计算P帧块与最佳匹配块的差值（去除时间冗余后的残差），对差值块复用I帧的JPEG压缩流程（DCT变换→量化→Z字形扫描→游程编码），最终压缩差值数据+匹配位置信息，相比I帧可实现更高压缩率。

\subparagraph{代码逻辑描述}
代码实现P帧压缩的核心流程：读取参考I帧和待压缩P帧并转换为Y亮度分量，补全尺寸后对每个P帧$8 \times 8$块执行块匹配（在$48 \times 64$搜索范围内计算所有候选块的MSE，选取最小值对应的最佳匹配块）；计算P帧块与最佳匹配块的差值，输出前2个块的匹配位置、MSE及差值作为中间验证数据；对差值块复用I帧的量化、Z字形扫描、游程编码流程，同时编码匹配位置信息；最终压缩差值数据+位置数据，计算P帧压缩率并与参考I帧的压缩率对比输出。

\begin{lstlisting}[caption={P帧压缩核心代码}, label={code:p_frame_compress}]
# 核心：块匹配（48x64范围找MSE最小的最佳匹配块）
best_matches = []
diff_blocks = []
search_range_x = 24  # 48范围：±24
search_range_y = 32  # 64范围：±32

for i in range(0, h_pad, 8):
    for j in range(0, w_pad, 8):
        p_block = p_Y_pad[i:i+8, j:j+8]
        start_x = max(0, j - search_range_x)
        end_x = min(w_pad - 8, j + search_range_x)
        start_y = max(0, i - search_range_y)
        end_y = min(h_pad - 8, i + search_range_y)
        
        min_mse = float('inf')
        best_pos = (j, i)
        for y in range(start_y, end_y + 1, 8):
            for x in range(start_x, end_x + 1, 8):
                i_block = i_Y_pad[y:y+8, x:x+8]
                mse = np.mean((p_block - i_block) ** 2)  # MSE计算
                if mse < min_mse:
                    min_mse = mse
                    best_pos = (x, y)
        
        best_i_block = i_Y_pad[best_pos[1]:best_pos[1]+8, best_pos[0]:best_pos[0]+8]
        diff_block = p_block - best_i_block  # 差值计算
        best_matches.append(best_pos)
        diff_blocks.append(diff_block)

# 核心：差值块编码（复用I帧JPEG流程）
quant_diff_blocks = [np.round(block / JPEG_LUMA_QUANT_TABLE) for block in diff_blocks]
run_length_diff = []
for block in quant_diff_blocks:
    zigzag_block = block.flatten()[ZIGZAG_ORDER]
    zero_count = 0
    for val in zigzag_block:
        if val == 0:
            zero_count += 1
        else:
            run_length_diff.append((zero_count, val))
            zero_count = 0
    run_length_diff.append((-1, -1))

# 压缩差值+匹配位置，计算压缩率
byte_diff = b''
for (zero, val) in run_length_diff:
    zero_int = int(zero)
    val_int = int(val)
    byte_diff += zero_int.to_bytes(2, byteorder='little', signed=True) + val_int.to_bytes(2, byteorder='little', signed=True)
byte_pos = b''
for (x, y) in best_matches:
    byte_pos += x.to_bytes(2, byteorder='little') + y.to_bytes(2, byteorder='little')
p_compressed_data = zlib.compress(byte_diff + byte_pos)
p_compression_ratio = (p_array.nbytes / 1024) / (len(p_compressed_data) / 1024)
\end{lstlisting}

\subsubsection{结果分析}

\paragraph{I帧JPEG压缩结果}

本次实验针对视频序列中\textbf{首I帧为黑帧}、中I帧及尾I帧开展JPEG标准压缩测试（含RGB-Y分量转换、8×8块DCT量化、游程编码），核心探究黑帧特性对压缩效率的影响，以及常规I帧的压缩规律。实验量化数据汇总于表\ref{tab:i_frame_jpeg_compression}，视觉化效果可参考首I帧压缩结果图（图\ref{fig:i_frame_compression_result}）及中、尾帧并列对比图（图\ref{fig:mid_last_frame_compression_result}），具体分析如下：

\begin{table}[htbp]
    \centering
    \caption{I帧JPEG压缩关键指标对比}
    \label{tab:i_frame_jpeg_compression}
    % 自适应页面宽度，高度等比例缩放
    \resizebox{\linewidth}{!}{
        \begin{tabular}{c r r r r}
            \toprule[1pt]
            帧类型 & {原始RGB大小(KB)} & {Y分量均值} & {压缩后大小(KB)} & {压缩率（原始:压缩后）} \\
            \midrule
            首I帧 & 2760.00 & -126.22 & 0.43 & 6452.60 \\
            中I帧 & 2760.00 & -104.19 & 14.48 & 190.64 \\
            尾I帧 & 2760.00 & -94.34 & 18.80 & 146.84 \\
            \bottomrule[1pt]
        \end{tabular}}
\end{table}

从表\ref{tab:i_frame_jpeg_compression}可知，三帧I帧的原始规格完全统一：分辨率均为640×368像素，原始RGB数据大小均为2760.00 KB。这一设定排除了图像尺寸、原始数据量差异对压缩结果的干扰，确保黑帧与常规I帧的压缩性能对比具备公平性与可比性。

全黑画面的所有像素RGB值趋近于0，转换为Y分量（亮度分量）后呈现“全局一致性”——首帧Y分量均值为-126.22（绝对值远高于中、尾帧），本质是黑帧像素的亮度值高度集中且接近最小值，图像空间冗余度达到理论极值（无任何亮度/纹理差异）。这一特征可从图\ref{fig:i_frame_compression_result}中直观验证：首帧压缩后的视觉效果无任何失真（全黑画面无细节可丢失）。

\begin{itemize}
    \item \textbf{DCT量化环节}：全黑画面的8×8像素块内所有像素值相同，DCT变换后仅直流分量（DC系数）非零，所有交流分量（AC系数）均为0（实验中首帧前2个8×8块量化结果已验证这一点）；
    \item \textbf{游程编码环节}：连续的零值AC系数仅需通过少量游程编码符号表征（如实验中前10个游程编码以“(0, 非零DC值)”和块分隔符为主），最终使首帧压缩后数据量仅0.43 KB（表\ref{tab:i_frame_jpeg_compression}），成为典型的“黑帧极致压缩”案例。
\end{itemize}

中、尾I帧为非黑帧（含正常画面纹理与亮度变化），其压缩表现反映了常规I帧的压缩规律：中帧Y分量均值为-104.19、尾帧为-94.34（表\ref{tab:i_frame_jpeg_compression}），绝对值远低于首黑帧，本质是画面包含亮度渐变、纹理细节（如图\ref{fig:mid_last_frame_compression_result}中中、尾帧可见的场景轮廓/明暗变化），像素值不再统一，空间冗余度显著降低。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\textwidth]{images/I_frame_first.png}  % 替换为实际图片路径
    \caption{I帧JPEG首帧压缩结果展示}
    \label{fig:i_frame_compression_result}  
\end{figure}

亮度/纹理的复杂性直接导致压缩效率下降：
\begin{itemize}
    \item 中帧压缩后数据量增至14.48 KB，压缩率降至190.64:1；
    \item 尾帧因画面细节进一步增加（亮度层次更丰富），压缩后数据量升至18.80 KB，压缩率仅146.84:1。
\end{itemize}

从编码环节看，非黑帧的8×8块像素值存在差异，DCT变换后虽仍以DC系数为主，但AC系数的“零值连续性”下降，游程编码需处理更多非零值，最终推高了压缩后数据量。

\begin{figure}[htbp]
    \centering
    % 子图1：中间帧
    \subfigure[I帧JPEG中间帧压缩结果]{
        \includegraphics[width=0.45\textwidth]{images/I_frame_mid.png}  
        \label{subfig:mid_frame_compression}
    }
    \hfill 
    \subfigure[I帧JPEG尾帧压缩结果]{
        \includegraphics[width=0.465\textwidth]{images/I_frame_last.png}  
        \label{subfig:last_frame_compression}
    }
    \caption{I帧JPEG中间帧与尾帧压缩结果展示}
    \label{fig:mid_last_frame_compression_result}  
\end{figure}

综上所述，I帧JPEG压缩实验验证了黑帧在压缩效率上的极致优势（压缩率高达6452.60:1），而常规I帧的压缩性能则受画面亮度/纹理复杂性影响显著，压缩率随之下降。该结果为理解不同类型I帧在MPEG压缩中的表现提供了实证依据。

\paragraph{P帧压缩实验结果分析}
本次实验针对P帧开展基于参考I帧的帧间预测压缩测试，核心对比P帧帧间编码与参考I帧帧内JPEG编码的压缩效率差异，实验视觉效果参考图\ref{fig:p_frame_compression_result}，量化数据汇总于表\ref{tab:i_p_frame_compression}，具体分析如下：
P帧采用“帧间块匹配+差值编码”的核心逻辑，以中I帧为参考帧，通过8×8块的像素匹配实现冗余剔除，关键特征体现在两方面：

% 导言区需加载：booktabs、siunitx、caption
\begin{table}[htbp]
    \centering
    \caption{I/P帧JPEG/帧间压缩关键指标对比}
    \label{tab:i_p_frame_compression}
    \resizebox{\linewidth}{!}{
        \begin{tabular}{crrrrr}
            \toprule[1pt]
            帧类型 & 原始RGB大小(KB) & Y分量均值 & 压缩后大小(KB) & 压缩率（原始:压缩后） \\
            \midrule
            首I帧（黑帧） & 2760.00 & -126.22 & 0.43 & 6452.60 \\
            中I帧（参考帧） & 2760.00 & -104.19 & 14.48 & 190.64 \\
            尾I帧 & 2760.00 & -94.34 & 18.80 & 146.84 \\
            P帧 & 2760.00 & -102.59 & 7.35 & 375.58 \\
            \bottomrule[1pt]
        \end{tabular}
    }
\end{table}

\begin{enumerate}
    {
    \item P帧与参考I帧的Y分量均值高度接近（P帧-102.59 vs 参考I帧-104.19，表\ref{tab:i_p_frame_compression}），反映两帧画面亮度分布几乎一致。实验中前2个P帧块的匹配结果验证了这一点：
    \begin{itemize}
        \item 块1（位置(0,0)）、块2（位置(0,8)）的最佳匹配位置均为(16, 32)，均方误差（MSE）仅0.03；
        \item MSE趋近于0说明匹配块与P帧块的像素值几乎无差异，帧间冗余度极高。
    \end{itemize}
    \item 因块匹配的高相似度，P帧块与参考帧匹配块的差值矩阵全为0（实验中块1差值矩阵无任何非零元素），这意味着P帧仅需存储“匹配位置信息”，无需额外编码像素差值——这是P帧压缩效率优于参考I帧的核心技术原因。
    }
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/P_frame_mid.png}  % 替换为实际图片路径
    \caption{P帧压缩结果展示}
    \label{fig:p_frame_compression_result}  
\end{figure}

\subsection{P帧与参考I帧的压缩效率对比}
从量化数据（表\ref{tab:i_p_frame_compression}）可清晰看出：
\begin{enumerate}
    \item 参考I帧（中I帧）采用帧内JPEG压缩后，数据量为14.48 KB，压缩率190.64:1；
    \item P帧采用帧间预测压缩后，数据量仅7.35 KB（仅包含匹配位置+极少量差值信息），压缩率提升至375.58:1，是参考I帧的1.97倍；
    \item 视觉层面（图\ref{fig:p_frame_compression_result}），P帧压缩后无任何视觉失真——因差值块全零，解码时可通过参考帧匹配位置完全还原P帧像素。
\end{enumerate}

\paragraph{P帧与其他I帧的压缩效率横向对比}
结合全量实验数据（表\ref{tab:i_p_frame_compression}），可进一步明确P帧的压缩特性：
\begin{itemize}
    \item P帧压缩率（375.58:1）远高于中I帧（190.64:1）、尾I帧（146.84:1），体现帧间编码对“连续帧低变化场景”的冗余剔除优势；
    \item 仅低于首I帧（黑帧，6452.60:1）——但首I帧的极致压缩源于“全黑画面的帧内绝对冗余”，属于特殊场景；而P帧的高压缩率是通用帧间编码的工程价值体现，更具普适性。
\end{itemize}

\paragraph{实验结论与工程启示}
本次P帧压缩实验验证了“帧间预测编码”对视频连续帧的压缩优势：
\begin{itemize}
    \item 技术层面：当P帧与参考I帧的画面相似度高（Y分量均值接近、MSE极低）时，帧间块匹配+差值编码可大幅降低数据量，压缩效率显著优于帧内JPEG编码；
    \item 工程层面：在视频编码系统中，对“低运动、低亮度变化”的连续帧，优先采用P帧帧间编码（而非全I帧帧内编码），可在保障画质的前提下将压缩率提升约1倍，大幅降低视频存储/传输成本；
    \item 场景适配：若视频序列存在大量连续相似帧（如监控、静态场景视频），P帧编码的优势会进一步放大，结合首I帧黑帧的极致压缩策略，可实现全序列的高效压缩。

\end{itemize}

综上，表\ref{tab:i_p_frame_compression}的量化数据与图\ref{fig:p_frame_compression_result}的视觉特征相互印证，证明帧间预测编码（P帧）是视频压缩中“平衡效率与画质”的核心技术路径。